{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Big_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinOriginal/news-recommender/blob/main/Big_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4qzK5QO4P98"
      },
      "source": [
        "from glob import glob\n",
        "import pandas as pd\n",
        "import pyarrow.parquet as pq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3IjicQX4b4_"
      },
      "source": [
        "import os, sys\n",
        "import pandas as pd \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv28jn-rd5m0",
        "outputId": "bf6ec995-093c-47f9-d93b-c8da1df8a6b1"
      },
      "source": [
        "# 구글 드라이브 사용 시 주석 해제\n",
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/mnt',force_remount=True)\n",
        "\n",
        "# Path에, 구글드라이브 내의 데이터 경로 설정\n",
        "path = '/content/mnt/MyDrive/colab_data/big_data/user_vector.parquet'\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom google.colab import drive\\ndrive.mount('/content/mnt',force_remount=True)\\n\\n# Path에, 구글드라이브 내의 데이터 경로 설정\\npath = '/content/mnt/MyDrive/colab_data/big_data/user_vector.parquet'\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUY1q0-mTqDo",
        "outputId": "ee1d2592-949f-418a-ae3c-473a7ef127ef"
      },
      "source": [
        "# GPU 할당 설정\n",
        "GPU_NUM = 0 # 원하는 GPU 번호 입력\n",
        "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.set_device(device) # change allocation of current GPU\n",
        "print ('Current cuda device ', torch.cuda.current_device()) # check\n",
        "\n",
        "# Additional Infos\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(GPU_NUM))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(GPU_NUM)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(GPU_NUM)/1024**3,1), 'GB')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current cuda device  0\n",
            "GeForce RTX 2060 SUPER\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.0 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIr6cTlW49Y9"
      },
      "source": [
        "# Read user_vector.parquet\n",
        "path = \"./data/user_vector.parquet\"\n",
        "df = pd.read_parquet(path) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nLf_d8TgJlV",
        "outputId": "44cd17c6-ba5b-4082-c27a-819fb7394346"
      },
      "source": [
        "#device = torch.device('cpu')\n",
        "# Convert to torch 데이터를 텐서로 불러옴. cpu에 올리는 이유는 램 부족 때문\n",
        "data = torch.DoubleTensor(df.values).to('cpu')\n",
        "print(\"전체 데이터 : \", data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([356295, 1422])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bfeJFQWTqDp",
        "outputId": "aaf8bfc9-7f44-407a-899d-d01bb2e851df"
      },
      "source": [
        "# 메인 유저 설정 (추천 받는 사용자)\n",
        "\n",
        "main_user = data[7].to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjq_3grSTqDq"
      },
      "source": [
        "# 비슷한 사용자를 몇 명 뽑을 것인지.\n",
        "\n",
        "num_k = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp-yX6LyTqDq",
        "outputId": "f330dfb0-ca25-4b8c-bc4a-1363d80334f9"
      },
      "source": [
        "# Cosine Similarity \n",
        "cos = nn.CosineSimilarity(dim= -1, eps=1e-6)\n",
        "\n",
        "# 높은 Cos값, 인덱스 저장할 리스트\n",
        "stored_index = []\n",
        "stored_values = []\n",
        "\n",
        "# VRAM 부족으로, 10만개씩 끊어서 계산\n",
        "# 10만개 당 cos_similarity 높은 num_k개씩 뽑아서 저장\n",
        "for i in range(0, int(data.shape[0]/100000)) : \n",
        "    torch.cuda.empty_cache()\n",
        "    val = cos(main_user,data[100000 * i : 100000 *i + 100000].to(device))\n",
        "    values, index = torch.topk(val,num_k)\n",
        "    index = index + 100000*i\n",
        "    stored_index.append(index)\n",
        "    stored_values.append(values)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "### 최종적으로 num_k개 유저 추리기\n",
        "#\n",
        "# 텐서로 변환\n",
        "stored_index = torch.cat(stored_index,0)\n",
        "stored_values = torch.cat(stored_values,0)\n",
        "print(stored_index,stored_values)\n",
        "\n",
        "# 상위 5개 추리기\n",
        "similar_values, index_of_stored_index = torch.topk(stored_values,num_k)\n",
        "\n",
        "# 인덱스 변환\n",
        "similar_index = []\n",
        "for i in index_of_stored_index :\n",
        "    print(i)\n",
        "    similar_index.append(stored_index[i])\n",
        "### 최종적으로 num_k개 유저 추리기 끝"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([     7,  74391,  58180,   3502,   1197, 177914, 190350, 110669, 192317,\n",
            "        169183, 231119, 225375, 222501, 244744, 224252], device='cuda:0') tensor([1.0000, 0.4472, 0.4472, 0.3651, 0.3651, 0.4743, 0.4472, 0.4472, 0.4472,\n",
            "        0.4472, 0.4743, 0.4472, 0.4472, 0.4472, 0.4472], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(10, device='cuda:0')\n",
            "tensor(5, device='cuda:0')\n",
            "tensor(2, device='cuda:0')\n",
            "tensor(1, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3jkkwjEAmqS",
        "outputId": "dedf0410-2d99-4a99-92b3-6d6d71d2e041"
      },
      "source": [
        "# num_k개 추린 유저들의 벡터를 similar_users에 저장\n",
        "similar_users = []\n",
        "for i in range(0,num_k) :\n",
        "  user_id = df.index[similar_index[i]]\n",
        "  similar_value = similar_values[i]\n",
        "  print(\"Index : {:10d}, ID : {:10s}, Similar Value : {}\".format(similar_index[i],user_id,similar_value))\n",
        "  similar_users.append(df.loc[user_id])\n",
        "\n",
        "similar_users = torch.DoubleTensor(k_rows)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index :          7, ID : 00004p2pq , Similar Value : 1.0\n",
            "Index :     231119, ID : noperCXP  , Similar Value : 0.4743416490252569\n",
            "Index :     177914, ID : knig2u7aR , Similar Value : 0.4743416490252569\n",
            "Index :      58180, ID : cwin25l1b , Similar Value : 0.4472135954999579\n",
            "Index :      74391, ID : dpem3RPfE , Similar Value : 0.4472135954999579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USWh7cXiByBh",
        "outputId": "d040667e-9de6-452f-c3f4-f27fd8a88eb8"
      },
      "source": [
        "# 벡터 체크\n",
        "similar_users.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 1422])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOWX-xGoCE-4",
        "outputId": "a06e8806-c237-4362-c79d-699e28428e82"
      },
      "source": [
        "# num_k명의 벡터 평균치 계산\n",
        "similar_users_mean = torch.mean(similar_users,dim=0)\n",
        "\n",
        "# 하나의 평균 벡터가 나옴\n",
        "similar_users_mean.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1422])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSJzsOyXPqyf"
      },
      "source": [
        "# num_k명의 평균 벡터와, 주인공 유저와의 벡터 차잇값을 계산\n",
        "diffence_val = torch.abs(similar_users_mean - main_user.cpu())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6APdcWhmQAyX"
      },
      "source": [
        "# 차이가 가장 많이 나는 값(뉴스) 추출. 차잇값, 인덱스 반환\n",
        "num_recommend_news = 5 # 추천할 뉴스의 갯수\n",
        "recommend_values, recommend_news_index = torch.topk(diffence_val,num_recommend_news)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2r1Xf_MRn5Z",
        "outputId": "573a7334-f402-47f9-cb03-c353bfc9a89e"
      },
      "source": [
        "# 추출된 인덱스에 해당하는 뉴스는, \n",
        "# 주인공 사용자는 보지 않았지만 비슷한 사용자들은 본 뉴스들이다.\n",
        "# 혹은, 주인공 사용자만 보고 비슷한 사용자들은 전부 보지 않은 뉴스들이다.\n",
        "\n",
        "print(\"추천도 : {}\".format(recommend_values))\n",
        "print(\"추천 뉴스의 data에서의 Columns 인덱스 : {}\".format(recommend_news_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "추천도 : tensor([0.8000, 0.8000, 0.8000, 0.6000, 0.6000], dtype=torch.float64)\n",
            "추천 뉴스의 data에서의 Columns 인덱스 : tensor([111, 487, 922, 673,  87])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HCBQ9k6QoWf",
        "outputId": "9d924451-cee2-44be-8926-8dbc96815ce3"
      },
      "source": [
        "base_address = \"https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid={}&aid={}\"\n",
        "# 추천 뉴스 출력\n",
        "for i in range(0, 5) :\n",
        "\n",
        "  ids = df.columns[recommend_news_index[i].item()]\n",
        "  oid = ids[4:7]\n",
        "  aid = ids[-10:]\n",
        "  #print(oid,aid)\n",
        "  print (base_address.format(oid,aid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=005&aid=0001308925\n",
            "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=022&aid=0003454387\n",
            "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=052&aid=0001425517\n",
            "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=025&aid=0002990918\n",
            "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=003&aid=0009801710\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqmJ3ABNRmLG",
        "outputId": "4fe70d1b-2547-4a4a-d259-f4f296461bdf"
      },
      "source": [
        "# 참고. 유저가 본 뉴스 목록들\n",
        "# user_index에 유저 인덱스 값을 넣으면 된다\n",
        "user_index = 7\n",
        "test_user_vector = torch.DoubleTensor(data[user_index])\n",
        "for i in range(0, test_user_vector.shape[0]) :\n",
        "  if test_user_vector[i] > 0 :\n",
        "    ids = df.columns[i]\n",
        "    oid = ids[4:7]\n",
        "    aid = ids[-10:]\n",
        "    #print(oid,aid)\n",
        "    print (base_address.format(oid,aid))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=003&aid=0009801710\n",
            "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=005&aid=0001308925\n",
            "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=022&aid=0003454387\n",
            "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=025&aid=0002990918\n",
            "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=025&aid=0002992042\n",
            "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=047&aid=0002266102\n",
            "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=052&aid=0001425517\n",
            "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=081&aid=0003082022\n",
            "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=081&aid=0003082072\n",
            "https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=437&aid=0000235831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr6tY4y5QlHQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}