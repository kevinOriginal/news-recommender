{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NCF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinOriginal/news-recommender/blob/main/NCF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04xPhha9oc2I"
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSQf-xo4J92i"
      },
      "source": [
        "from glob import glob\n",
        "import pandas as pd\n",
        "import pyarrow.parquet as pq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36rUYHxMKEVf"
      },
      "source": [
        "import os, sys\n",
        "import pandas as pd \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIXx73CeKFxM",
        "outputId": "dfa0c599-6f7e-47d1-c507-e770274d68b8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/mnt',force_remount=True)\n",
        "\n",
        "path = '/content/mnt/My Drive/Colab Notebooks/user_vector.parquet'\n",
        "path2 = '/content/mnt/My Drive/Colab Notebooks/data-frame.parquet'\n",
        "path3 = '/content/mnt/My Drive/Colab Notebooks/comments_index.csv'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/mnt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBnTI2SxN99k",
        "outputId": "5042ad32-cf9e-4de5-a6e3-22f1e5f90e01"
      },
      "source": [
        "# Read user_vector.parquet\n",
        "df = pd.read_parquet(path) \n",
        "print(\"dtype: \", df.to_numpy().dtype)\n",
        "# news_id_list = df.columns\n",
        "# user_id_list = df.index.values\n",
        "# print(user_id_list)\n",
        "# print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dtype:  uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks7HVYLYg1lt",
        "outputId": "8d62bf57-0a97-484c-fd4f-84765d8c6bda"
      },
      "source": [
        "# news_df = pd.read_csv(path3)\n",
        "news_df = pd.read_parquet(path2)\n",
        "# news_df = news_df.to_numpy()\n",
        "# print(\"dtype: \", news_df.dtype)\n",
        "# news_df.astype(str)\n",
        "# print(\"New dtype: \", news_df.dtype)\n",
        "# news_df.userId.apply(str)\n",
        "# news_df.objectId.apply(str)\n",
        "# news_df.sympathyCount.apply(int)\n",
        "# news_df.antipathyCount.apply(int)\n",
        "\n",
        "\n",
        "# print(shit)\n",
        "news_df['marked'] = 1\n",
        "\n",
        "news_df = news_df.reset_index()[['userId', 'objectId', 'sympathyCount', 'antipathyCount', 'marked']]\n",
        "news_df['marked'] = 1\n",
        "news_df_arr = news_df.to_numpy()\n",
        "news_df_arr.astype(np.string_)\n",
        "# news_df['userId'].astype(np.string_)\n",
        "# news_df['objectId'].astype(np.string_)\n",
        "\n",
        "print(news_df.head())\n",
        "print(news_df.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      userId            objectId  sympathyCount  antipathyCount  marked\n",
            "0  rudd1kmeI  news008,0004390397           8564              91       1\n",
            "1  edmo28lVR  news008,0004390397           5340              84       1\n",
            "2  jinh3V2DH  news008,0004390397           4757             992       1\n",
            "3  jgb72DP5v  news008,0004390397           2193              46       1\n",
            "4  paki2eFia  news008,0004390397           1926              63       1\n",
            "Index(['userId', 'objectId', 'sympathyCount', 'antipathyCount', 'marked'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLXClbj9RtU3"
      },
      "source": [
        "# data = torch.DoubleTensor(df.values)\n",
        "# print(\"전체 데이터 : \", data.shape)\n",
        "# print(\"shape[0] : \", data.shape[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "LeRAR02asGmT",
        "outputId": "0eab01ef-0110-41e9-aa78-7c714cc78e00"
      },
      "source": [
        "train_df, valid_df = train_test_split(news_df, test_size=0.2)\n",
        "\n",
        "train_df = train_df.reset_index()[['userId', 'objectId', 'sympathyCount', 'antipathyCount', 'marked']]\n",
        "valid_df = valid_df.reset_index()[['userId', 'objectId', 'sympathyCount', 'antipathyCount', 'marked']]\n",
        "\n",
        "# train_df.head()\n",
        "valid_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>objectId</th>\n",
              "      <th>sympathyCount</th>\n",
              "      <th>antipathyCount</th>\n",
              "      <th>marked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kmjn2jbJX</td>\n",
              "      <td>news005,0001310058</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spea7QAMT</td>\n",
              "      <td>news008,0004394376</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ehle1wNG6</td>\n",
              "      <td>news025,0002991962</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>insonAT3</td>\n",
              "      <td>news001,0011542145</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rara9gh8r</td>\n",
              "      <td>news025,0002992089</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      userId            objectId  sympathyCount  antipathyCount  marked\n",
              "0  kmjn2jbJX  news005,0001310058              5              18       1\n",
              "1  spea7QAMT  news008,0004394376              0               0       1\n",
              "2  ehle1wNG6  news025,0002991962              0               0       1\n",
              "3   insonAT3  news001,0011542145              0               0       1\n",
              "4  rara9gh8r  news025,0002992089              0               0       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouP30JNgrn2T"
      },
      "source": [
        "def encode_column(column):\n",
        "    \"\"\" Encodes a pandas column with continous IDs\"\"\"\n",
        "    keys = column.unique()\n",
        "    key_to_id = {key:idx for idx,key in enumerate(keys)}\n",
        "    return key_to_id, np.array([key_to_id[x] for x in column]), len(keys)\n",
        "\n",
        "def encode_df(df):\n",
        "    \"\"\"Encodes rating data with continuous user and news ids\"\"\"\n",
        "    \n",
        "    news_ids, df['objectId'], num_news = encode_column(df['objectId'])\n",
        "    user_ids, df['userId'], num_users = encode_column(df['userId'])\n",
        "    return df, num_users, num_news, user_ids, news_ids\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5yN1geHsS4v",
        "outputId": "e87528cd-d4c4-4485-a077-f2c12e7507ba"
      },
      "source": [
        "train_df, num_users, num_news, user_ids, news_ids = encode_df(train_df)\n",
        "\n",
        "Y = create_sparse_matrix(train_df, num_users, num_news)\n",
        "print(\"Number of users :\", num_users)\n",
        "print(\"Number of news :\", num_news)\n",
        "print(\"userid values\", train_df['userId'].values)\n",
        "print(\"userid values\", train_df['objectId'].values)\n",
        "\n",
        "\n",
        "\n",
        "Y.todense()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users : 326260\n",
            "Number of news : 1422\n",
            "userid values [     0      1      2 ... 112765 182911  14284]\n",
            "userid values [  0   1   2 ... 592 725 831]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[1, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 1, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y3GAK9fYf2L"
      },
      "source": [
        "def create_sparse_matrix(df, rows, cols, column_name = 'marked'):\n",
        "    \"\"\" Returns a sparse utility matrix\"\"\" \n",
        "    val_1 = df['userId'].values\n",
        "    val_1.astype('str')\n",
        "    val_2 = df['objectId'].values\n",
        "    val_2.astype('str')\n",
        "    val_0 = df[column_name].values\n",
        "    val_0.astype('str')\n",
        "    return sparse.csc_matrix((val_0, (val_1, val_2)),shape=(rows, cols), dtype='string')\n",
        "\n",
        "\n",
        "def create_embeddings(n, K):\n",
        "    \"\"\"\n",
        "    Creates a random numpy matrix of shape n, K with uniform values in (0, 11/K)\n",
        "    n: number of items/users\n",
        "    K: number of factors in the embedding \n",
        "    \"\"\"\n",
        "    return 11*np.random.random((n, K)) / K\n",
        "\n",
        "# emb_sample = create_embeddings(1422, 3)\n",
        "# print(emb_sample.shape[0])\n",
        "# print(emb_sample.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQVu8Ks5KHR5"
      },
      "source": [
        "lmbda = 0.0002\n",
        "\n",
        "\n",
        "def predict(df, emb_user, emb_news):\n",
        "    \"\"\" This function computes df[\"prediction\"] without doing (U*V^T).\n",
        "    \n",
        "    Computes df[\"prediction\"] by using elementwise multiplication of the corresponding embeddings and then \n",
        "    sum to get the prediction u_i*v_j. This avoids creating the dense matrix U*V^T.\n",
        "    \"\"\"\n",
        "    df['prediction'] = np.sum(np.multiply(emb_news[df['objectId']],emb_user[df['userId']]), axis=1)\n",
        "    return df\n",
        "    \n",
        "\n",
        "def cost(df, emb_user, emb_news):\n",
        "    \"\"\" Computes mean square error\"\"\"\n",
        "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_news.shape[0])\n",
        "    predicted = create_sparse_matrix(predict(df, emb_user, emb_news), emb_user.shape[0], emb_news.shape[0], 'prediction')\n",
        "    return np.sum((Y-predicted).power(2))/df.shape[0] \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V5TtetKQTX9"
      },
      "source": [
        "def gradient(df, emb_user, emb_news):\n",
        "    \"\"\" Computes the gradient for user and news embeddings\"\"\"\n",
        "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_news.shape[0])\n",
        "    predicted = create_sparse_matrix(predict(df, emb_user, emb_news), emb_user.shape[0], emb_news.shape[0], 'prediction')\n",
        "    delta =(Y-predicted)\n",
        "    grad_user = (-2/df.shape[0])*(delta*emb_news) + 2*lmbda*emb_user\n",
        "    grad_news = (-2/df.shape[0])*(delta.T*emb_news) + 2*lmbda*emb_news\n",
        "    return grad_user, grad_news\n",
        "\n",
        "\n",
        "def gradient_descent(df, emb_user, emb_news, iterations=2000, learning_rate=0.01, df_val=None):\n",
        "    \"\"\" \n",
        "    Computes gradient descent with momentum (0.9) for given number of iterations.\n",
        "    emb_user: the trained user embedding\n",
        "    emb_news: the trained news embedding\n",
        "    \"\"\"\n",
        "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_news.shape[0])\n",
        "    beta = 0.9\n",
        "    grad_user, grad_news = gradient(df, emb_user, emb_news)\n",
        "    v_user = grad_user\n",
        "    v_news = grad_news\n",
        "    print(\"shit\")\n",
        "    for i in range(iterations):\n",
        "        grad_user, grad_news = gradient(df, emb_user, emb_news)\n",
        "        v_user = beta*v_user + (1-beta)*grad_user\n",
        "        v_news = beta*v_news + (1-beta)*grad_news\n",
        "        emb_user = emb_user - learning_rate*v_user\n",
        "        emb_news = emb_news - learning_rate*v_news\n",
        "        if(not (i+1)%50):\n",
        "            print(\"\\niteration\", i+1, \":\")\n",
        "            print(\"train mse:\",  cost(df, emb_user, emb_news))\n",
        "            if df_val is not None:\n",
        "                print(\"validation mse:\",  cost(df_val, emb_user, emb_news))\n",
        "    return emb_user, emb_news"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "ZbSapcX5U9Ck",
        "outputId": "d1d1b6b0-b0ff-4b6b-d70c-08e33d5df23b"
      },
      "source": [
        "print(\"user num\", num_users)\n",
        "print(\"news num\", num_news)\n",
        "\n",
        "emb_user = create_embeddings(num_users, 3)\n",
        "emb_news = create_embeddings(num_news, 3)\n",
        "\n",
        "Y = create_sparse_matrix(news_df, emb_user.shape[0], emb_news.shape[0])\n",
        "\n",
        "\n",
        "emb_user, emb_news = gradient_descent(news_df, emb_user, emb_news, iterations=800, learning_rate=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0aae7afbdf7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"user num\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"news num\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_news\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0memb_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0memb_news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_news\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_users' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gQK_EpQI1Z6",
        "outputId": "a05caaef-d1df-4cf6-cc49-f9b96497b079"
      },
      "source": [
        "print(\"Test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIYhgB0mI0g-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq22A6PuIwyE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}